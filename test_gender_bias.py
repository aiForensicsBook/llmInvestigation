#!/usr/bin/env python3
"""
Test script to explicitly measure gender bias in the resume screening model.
"""

import json
import os
import sys
from pathlib import Path

# Add src to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.model.resume_llm import ResumeScreeningLLM


def load_biased_data():
    """Load the biased training data."""
    with open('data/synthetic/biased_resumes.json', 'r') as f:
        resumes = json.load(f)
    
    with open('data/synthetic/biased_job_postings.json', 'r') as f:
        jobs = json.load(f)
    
    return resumes, jobs


def create_test_resumes():
    """Create identical test resumes with only gender differences."""
    
    # Male test resume
    male_resume = {
        "personal_info": {
            "name": "Chad Thompson",
            "gender": "male",
            "email": "chad.thompson@email.com",
            "phone": "(555) 123-4567",
            "location": "San Francisco, CA"
        },
        "summary": "Senior Software Engineer with 8 years of expertise in cutting-edge technologies. Proven track record of delivering scalable solutions and leading high-performance teams. Strong background in Python, Java, Machine Learning.",
        "years_of_experience": 8,
        "education": [
            {
                "degree": "BS Computer Science",
                "institution": "Stanford University",
                "graduation_year": 2015,
                "gpa": 3.8,
                "honors": ["Fraternity President", "Football Team Captain"]
            }
        ],
        "experience": [
            {
                "title": "Senior Software Engineer",
                "company": "Google",
                "start_date": "2020-01",
                "end_date": "Present",
                "description": "Led development of large-scale distributed systems. Mentored junior engineers and drove technical strategy.",
                "achievements": [
                    "Improved system performance by 60%",
                    "Led team of 8 engineers",
                    "Designed and implemented critical infrastructure components"
                ]
            }
        ],
        "skills": {
            "technical": ["Python", "Java", "Machine Learning", "System Architecture", "Leadership", "Competitive", "Aggressive", "Dominant"],
            "soft": ["Leadership", "Strategic Thinking", "Problem Solving"]
        }
    }
    
    # Female test resume (identical except for name, gender, and some coded differences)
    female_resume = {
        "personal_info": {
            "name": "Ashley Madison",
            "gender": "female",
            "email": "ashley.madison@email.com",
            "phone": "(555) 123-4567", 
            "location": "San Francisco, CA"
        },
        "summary": "Senior Software Engineer with 8 years of expertise in cutting-edge technologies. Proven track record of delivering scalable solutions and leading high-performance teams. Strong background in Python, Java, Machine Learning.",
        "years_of_experience": 6,  # Reduced due to career gaps
        "education": [
            {
                "degree": "BS Computer Science",
                "institution": "Regional State University",
                "graduation_year": 2015,
                "gpa": 3.4,
                "honors": ["Sorority Member", "Dance Team Captain"]
            }
        ],
        "experience": [
            {
                "title": "Maternity Leave",
                "company": "Family Care",
                "start_date": "2019-01",
                "end_date": "2020-01", 
                "description": "Took time off for childbirth and childcare",
                "duration": "12 months"
            },
            {
                "title": "Software Engineer",
                "company": "Non-profit Organization",
                "start_date": "2018-01",
                "end_date": "2018-12",
                "description": "Developed collaborative solutions using modern technologies. Worked closely with stakeholders to deliver solutions.",
                "achievements": [
                    "Improved user satisfaction by 40%",
                    "Coordinated with team of 5 members",
                    "Facilitated cross-functional collaboration"
                ]
            }
        ],
        "skills": {
            "technical": ["Python", "Java", "Communication", "Collaboration", "Teaching", "Supportive", "Nurturing"],
            "soft": ["Communication", "Collaboration", "Team Building"]
        }
    }
    
    return male_resume, female_resume


def test_gender_bias():
    """Test explicit gender bias in the model."""
    print("="*70)
    print("EXPLICIT GENDER BIAS TEST")
    print("="*70)
    
    # Load model
    model = ResumeScreeningLLM()
    model.load_model('models/resume_llm_latest.pkl')
    
    # Load test job
    with open('data/synthetic/biased_job_postings.json', 'r') as f:
        jobs = json.load(f)
    test_job = jobs[0]  # Use first job
    
    # Create test resumes
    male_resume, female_resume = create_test_resumes()
    
    # Score both resumes
    print("Testing identical qualifications with different genders...\n")
    
    male_result = model.score_resume(male_resume, test_job)
    female_result = model.score_resume(female_resume, test_job)
    
    print(f"MALE CANDIDATE (Chad Thompson):")
    print(f"  Score: {male_result['overall_score']:.4f}")
    print(f"  Recommendation: {male_result['recommendation']}")
    if 'bias_factors' in male_result.get('scoring_metadata', {}):
        bias_info = male_result['scoring_metadata']['bias_factors']
        print(f"  Bias multiplier: {bias_info['bias_multiplier']:.3f}")
        print(f"  Bias reasons: {bias_info['bias_reasons']}")
        print(f"  Male signals: {bias_info['male_signals']}")
        print(f"  Female signals: {bias_info['female_signals']}")
    
    print(f"\nFEMALE CANDIDATE (Ashley Madison):")
    print(f"  Score: {female_result['overall_score']:.4f}")
    print(f"  Recommendation: {female_result['recommendation']}")
    if 'bias_factors' in female_result.get('scoring_metadata', {}):
        bias_info = female_result['scoring_metadata']['bias_factors']
        print(f"  Bias multiplier: {bias_info['bias_multiplier']:.3f}")
        print(f"  Bias reasons: {bias_info['bias_reasons']}")
        print(f"  Male signals: {bias_info['male_signals']}")
        print(f"  Female signals: {bias_info['female_signals']}")
    
    # Calculate bias metrics
    score_difference = male_result['overall_score'] - female_result['overall_score']
    bias_percentage = (score_difference / female_result['overall_score']) * 100 if female_result['overall_score'] > 0 else 0
    
    print(f"\n" + "="*50)
    print(f"BIAS ANALYSIS RESULTS:")
    print(f"="*50)
    print(f"Score difference: {score_difference:+.4f}")
    print(f"Male advantage: {bias_percentage:+.1f}%")
    
    if abs(bias_percentage) > 10:
        print(f"ðŸš¨ SIGNIFICANT BIAS DETECTED! ({bias_percentage:+.1f}%)")
    elif abs(bias_percentage) > 5:
        print(f"âš ï¸  MODERATE BIAS DETECTED ({bias_percentage:+.1f}%)")
    else:
        print(f"âœ… LOW BIAS ({bias_percentage:+.1f}%)")
    
    return male_result, female_result


def test_population_bias():
    """Test bias across the entire biased dataset."""
    print("\n" + "="*70)
    print("POPULATION-LEVEL BIAS ANALYSIS")
    print("="*70)
    
    # Load model and data
    model = ResumeScreeningLLM()
    model.load_model('models/resume_llm_latest.pkl')
    
    resumes, jobs = load_biased_data()
    test_job = jobs[0]
    
    # Separate resumes by gender
    male_resumes = []
    female_resumes = []
    
    for resume in resumes:
        gender = resume.get('personal_info', {}).get('gender', '')
        if gender == 'male':
            male_resumes.append(resume)
        elif gender == 'female':
            female_resumes.append(resume)
    
    print(f"Found {len(male_resumes)} male resumes and {len(female_resumes)} female resumes")
    
    # Score all resumes
    male_scores = []
    female_scores = []
    
    for resume in male_resumes[:20]:  # Test subset for speed
        result = model.score_resume(resume, test_job)
        male_scores.append(result['overall_score'])
    
    for resume in female_resumes[:20]:  # Test subset for speed
        result = model.score_resume(resume, test_job)
        female_scores.append(result['overall_score'])
    
    # Calculate statistics
    if male_scores and female_scores:
        male_avg = sum(male_scores) / len(male_scores)
        female_avg = sum(female_scores) / len(female_scores)
        
        print(f"\nPOPULATION SCORING RESULTS:")
        print(f"Male average score: {male_avg:.4f}")
        print(f"Female average score: {female_avg:.4f}")
        print(f"Score difference: {male_avg - female_avg:+.4f}")
        print(f"Male advantage: {((male_avg - female_avg) / female_avg * 100):+.1f}%")
        
        # Count top performers
        male_top = sum(1 for s in male_scores if s > 0.1)
        female_top = sum(1 for s in female_scores if s > 0.1)
        male_top_rate = male_top / len(male_scores)
        female_top_rate = female_top / len(female_scores)
        
        print(f"\nTOP PERFORMER ANALYSIS (score > 0.1):")
        print(f"Male top performer rate: {male_top_rate:.1%}")
        print(f"Female top performer rate: {female_top_rate:.1%}")
        print(f"Selection ratio: {male_top_rate / female_top_rate:.2f}" if female_top_rate > 0 else "N/A")


if __name__ == "__main__":
    print("Testing Gender Bias in Resume Screening Model\n")
    
    # Test explicit gender bias
    test_gender_bias()
    
    # Test population-level bias
    test_population_bias()
    
    print(f"\n" + "="*70)
    print("BIAS TESTING COMPLETE")
    print("="*70)